# -*- coding: utf-8 -*-
"""AoL.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/148q6cITUe08g_7gNFYEeLPKG84-1u0yx
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import pylab as pl
import numpy as np
import scipy.optimize as opt
from sklearn import preprocessing
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn import svm
from sklearn.metrics import accuracy_score
# %matplotlib inline
import matplotlib.pyplot as plt

# Memanggil Data
dataset = pd.read_csv('/content/diabetes.csv')

# Isi dari dataset
dataset.head(10)

# Ukuran dari dataset (baris, kolom)
dataset.shape

# properti-properti statistikal dari dataset
dataset.describe()

# Frekuensi masing-masing outcome
dataset['Outcome'].value_counts()

# Rerataan dari tiap kolom group by outcome
dataset.groupby('Outcome').mean()

# Memisahkan table
X = dataset.drop(columns = 'Outcome', axis = 1)
Y = dataset['Outcome']

print(X)
print(Y)

"""Standarisasi Data"""

scaler = StandardScaler()
X = X.values
scaler.fit(X)
standarized_data = scaler.transform(X)

print(standarized_data)

X = standarized_data

print(X)
print(Y)

"""Train Data Split

"""

X_train, X_test, Y_train, Y_test  = train_test_split(X, Y, test_size = 0.2, stratify =  Y, random_state = 2)

print(X.shape, X_train.shape, X_test.shape)

"""Training Model

"""

classifier = svm.SVC(kernel='linear')

# X_train = X_train.values
Y_train = Y_train.values
classifier.fit(X_train, Y_train)

"""Performance Evaluation"""

# Accuracy score on the training data
X_train_predict = classifier.predict(X_train)
training_data_accuracy = accuracy_score(X_train_predict, Y_train)

print('Accuracy score of the training data : ', training_data_accuracy)

# Accuracy score on the test data
X_test_predict = classifier.predict(X_test)
test_data_accuracy = accuracy_score(X_test_predict, Y_test)

print('Accuracy score of the test data : ', test_data_accuracy)

from sklearn.metrics import classification_report, confusion_matrix
import itertools

def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix',
                          cmap=plt.cm.Greens):
    """
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    print(cm)

    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    fmt = '.2f' if normalize else 'd'
    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, format(cm[i, j], fmt),
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')

cnf_matrix = confusion_matrix(Y_test, X_test_predict, labels=[0,1])
np.set_printoptions(precision=6)

plt.figure()
plot_confusion_matrix(cnf_matrix, classes=['not_diabetes(0)','diabetes(1)'],normalize= False,  title='Confusion matrix')

print (classification_report(Y_test, X_test_predict))

"""Sistem Prediksi"""

input_data = (4,147,74,25,293,34.9,0.385,30)

# ubah jadi numpy array
input_data_np_arr = np.asanyarray(input_data)

# reshape
input_data_reshaped = input_data_np_arr.reshape(1,-1)

# standarisasi input
std_data = scaler.transform(input_data_reshaped)

prediction = classifier.predict(std_data)
# print(prediction)

if prediction[0] == 1:
  print("You are diagnosed with diabetes")
else:
  print("You aren't diagnosed with diabetes")

input_data = (4,146,78,0,0,38.5,0.52,67)

# ubah jadi numpy array
input_data_np_arr = np.asanyarray(input_data)

# reshape
input_data_reshaped = input_data_np_arr.reshape(1,-1)

# standarisasi input
std_data = scaler.transform(input_data_reshaped)

prediction = classifier.predict(std_data)
# print(prediction)

if prediction[0] == 1:
  print("You are diagnosed with diabetes")
else:
  print("You aren't diagnosed with diabetes")

"""Pickle

"""

import pickle
filename = 'model-diabetes.pkl'
pickle.dump(classifier, open(filename, 'wb'))